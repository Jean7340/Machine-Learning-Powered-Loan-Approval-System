{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "c80dd604",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.linear_model import LassoCV\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from collections import Counter\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Read in dataset\n",
                "df = pd.read_csv(\"heloc_dataset_v1.csv\")\n",
                "df.head(3)\n",
                "\n",
                "# Remove rows with missing values\n",
                "df = df[~df.isin([-9]).any(axis=1)]\n",
                "\n",
                "# Calculate group means for numerical columns where -7 needs to be replaced\n",
                "group_means = df.replace(-7, np.nan).groupby('RiskPerformance').mean()\n",
                "\n",
                "# Function to impute -7 with group means based on Risk_Performance\n",
                "def impute_with_group_mean(row):\n",
                "    for col in df.columns:\n",
                "        # Skip non-numerical columns (like 'Risk_Performance')\n",
                "        if col == 'RiskPerformance' or not np.issubdtype(df[col].dtype, np.number):\n",
                "            continue\n",
                "        # Replace -7 with the corresponding group's mean\n",
                "        if row[col] == -7:\n",
                "            row[col] = group_means.loc[row['RiskPerformance'], col]\n",
                "    return row\n",
                "\n",
                "# Apply the function row by row\n",
                "df = df.apply(impute_with_group_mean, axis=1)\n",
                "\n",
                "\n",
                "\n",
                "# Check and remove duplicate rows\n",
                "duplicates = df.duplicated()\n",
                "num_duplicates = duplicates.sum()\n",
                "#print(f\"Number of duplicate rows: {num_duplicates}\")\n",
                "\n",
                "duplicate_rows = df[duplicates]\n",
                "#print(\"Duplicate rows:\\n\", duplicate_rows)\n",
                "\n",
                "df = df.drop_duplicates()\n",
                "\n",
                "\n",
                "label_encoder = LabelEncoder()\n",
                "\n",
                "# Separate features and target variable\n",
                "X = df.drop(columns=['RiskPerformance'])\n",
                "y = label_encoder.fit_transform(df['RiskPerformance'])\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "# Apply Lasso regression with cross-validation\n",
                "lasso = LassoCV(cv=5, random_state=42)\n",
                "lasso.fit(X_scaled, y)\n",
                "\n",
                "# Extract feature importance\n",
                "lasso_importance = pd.Series(lasso.coef_, index=X.columns)\n",
                "important_features = lasso_importance[lasso_importance != 0].sort_values(ascending=False)\n",
                "\n",
                "# Print the top 10 most important features\n",
                "top_n = 24\n",
                "print(f\"Top {top_n} Important Features Based on Lasso Regression:\")\n",
                "print(important_features.head(top_n))\n",
                "\n",
                "# Class Imbalance\n",
                "counts = df[\"RiskPerformance\"].value_counts()\n",
                "print(\"Counts of 'Bad' vs 'Good':\")\n",
                "print(counts)\n",
                "\n",
                "# Step 2: Split the data into train and test sets (80% train, 20% test)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "smote = SMOTE(random_state=42)\n",
                "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "# New class distribution\n",
                "print(\"Resampled class distribution:\", Counter(y_resampled))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d20d9b59-debd-4b7d-b58c-9e9aa72e0fcd",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2a26d205-eef7-4177-8cf0-88676917184c",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 [3.10]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}